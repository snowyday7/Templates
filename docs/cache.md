# ç¼“å­˜æ¶ˆæ¯æ¨¡å—ä½¿ç”¨æŒ‡å—

ç¼“å­˜æ¶ˆæ¯æ¨¡å—æä¾›äº†Redisç¼“å­˜ç®¡ç†ã€Celeryå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰åŠŸèƒ½ï¼Œå¸®åŠ©æå‡åº”ç”¨æ€§èƒ½å’Œå¤„ç†èƒ½åŠ›ã€‚

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [åŸºç¡€ä½¿ç”¨](#åŸºç¡€ä½¿ç”¨)
- [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install redis celery[redis] kombu
```

### åŸºç¡€é…ç½®

```python
from templates.cache import RedisManager, CeleryManager, CacheConfig

# åˆ›å»ºç¼“å­˜é…ç½®
cache_config = CacheConfig(
    REDIS_HOST="localhost",
    REDIS_PORT=6379,
    REDIS_DB=0,
    REDIS_PASSWORD=None,
    CACHE_DEFAULT_TIMEOUT=300
)

# åˆ›å»ºRedisç®¡ç†å™¨
redis_manager = RedisManager(cache_config)

# åˆ›å»ºCeleryç®¡ç†å™¨
celery_manager = CeleryManager(
    broker_url="redis://localhost:6379/0",
    result_backend="redis://localhost:6379/0"
)
```

## âš™ï¸ é…ç½®è¯´æ˜

### CacheConfig å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `REDIS_HOST` | str | "localhost" | Redisä¸»æœºåœ°å€ |
| `REDIS_PORT` | int | 6379 | Redisç«¯å£ |
| `REDIS_DB` | int | 0 | Redisæ•°æ®åº“ç¼–å· |
| `REDIS_PASSWORD` | str | None | Rediså¯†ç  |
| `REDIS_MAX_CONNECTIONS` | int | 20 | æœ€å¤§è¿æ¥æ•° |
| `REDIS_SOCKET_TIMEOUT` | int | 5 | å¥—æ¥å­—è¶…æ—¶æ—¶é—´(ç§’) |
| `REDIS_CONNECTION_TIMEOUT` | int | 5 | è¿æ¥è¶…æ—¶æ—¶é—´(ç§’) |
| `CACHE_DEFAULT_TIMEOUT` | int | 300 | é»˜è®¤ç¼“å­˜è¶…æ—¶æ—¶é—´(ç§’) |
| `CACHE_KEY_PREFIX` | str | "myapp" | ç¼“å­˜é”®å‰ç¼€ |
| `CACHE_VERSION` | int | 1 | ç¼“å­˜ç‰ˆæœ¬ |

### Celeryé…ç½®å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `CELERY_BROKER_URL` | str | å¿…å¡« | æ¶ˆæ¯ä»£ç†URL |
| `CELERY_RESULT_BACKEND` | str | å¿…å¡« | ç»“æœåç«¯URL |
| `CELERY_TASK_SERIALIZER` | str | "json" | ä»»åŠ¡åºåˆ—åŒ–æ ¼å¼ |
| `CELERY_RESULT_SERIALIZER` | str | "json" | ç»“æœåºåˆ—åŒ–æ ¼å¼ |
| `CELERY_ACCEPT_CONTENT` | list | ["json"] | æ¥å—çš„å†…å®¹ç±»å‹ |
| `CELERY_TIMEZONE` | str | "UTC" | æ—¶åŒº |
| `CELERY_ENABLE_UTC` | bool | True | å¯ç”¨UTC |
| `CELERY_TASK_ROUTES` | dict | {} | ä»»åŠ¡è·¯ç”±é…ç½® |
| `CELERY_WORKER_CONCURRENCY` | int | 4 | å·¥ä½œè¿›ç¨‹å¹¶å‘æ•° |

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_MAX_CONNECTIONS=20
CACHE_DEFAULT_TIMEOUT=300
CACHE_KEY_PREFIX=myapp

CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
CELERY_WORKER_CONCURRENCY=4
CELERY_TIMEZONE=Asia/Shanghai
```

## ğŸ’» åŸºç¡€ä½¿ç”¨

### 1. Redisç¼“å­˜æ“ä½œ

```python
from templates.cache import RedisManager
import json
from datetime import timedelta

# åŸºç¡€ç¼“å­˜æ“ä½œ
async def cache_examples():
    # è®¾ç½®ç¼“å­˜
    await redis_manager.set("user:1", {"name": "John", "age": 30}, timeout=3600)
    
    # è·å–ç¼“å­˜
    user_data = await redis_manager.get("user:1")
    print(user_data)  # {'name': 'John', 'age': 30}
    
    # æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨
    exists = await redis_manager.exists("user:1")
    print(exists)  # True
    
    # åˆ é™¤ç¼“å­˜
    await redis_manager.delete("user:1")
    
    # æ‰¹é‡æ“ä½œ
    await redis_manager.set_many({
        "user:1": {"name": "John"},
        "user:2": {"name": "Jane"},
        "user:3": {"name": "Bob"}
    }, timeout=1800)
    
    users = await redis_manager.get_many(["user:1", "user:2", "user:3"])
    print(users)  # [{'name': 'John'}, {'name': 'Jane'}, {'name': 'Bob'}]
    
    # åˆ é™¤åŒ¹é…æ¨¡å¼çš„é”®
    await redis_manager.delete_pattern("user:*")

# ç¼“å­˜è£…é¥°å™¨
from templates.cache import cache_result

@cache_result(timeout=600, key_prefix="api_data")
async def get_expensive_data(user_id: int, category: str):
    """æ¨¡æ‹Ÿè€—æ—¶çš„æ•°æ®è·å–æ“ä½œ"""
    await asyncio.sleep(2)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    return {
        "user_id": user_id,
        "category": category,
        "data": f"expensive data for user {user_id}",
        "timestamp": datetime.utcnow().isoformat()
    }

# ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨
result = await get_expensive_data(123, "products")
# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šæ‰§è¡Œå‡½æ•°ï¼Œåç»­è°ƒç”¨ä¼šä»ç¼“å­˜è¿”å›
```

### 2. Celeryå¼‚æ­¥ä»»åŠ¡

```python
from templates.cache import CeleryManager
from celery import Celery

# åˆ›å»ºCeleryåº”ç”¨
celery_app = celery_manager.create_app()

# å®šä¹‰ä»»åŠ¡
@celery_app.task(bind=True, max_retries=3)
def send_email_task(self, to_email: str, subject: str, content: str):
    """å‘é€é‚®ä»¶ä»»åŠ¡"""
    try:
        # æ¨¡æ‹Ÿå‘é€é‚®ä»¶
        import time
        time.sleep(2)  # æ¨¡æ‹Ÿé‚®ä»¶å‘é€æ—¶é—´
        
        print(f"Email sent to {to_email}: {subject}")
        return {"status": "success", "email": to_email}
        
    except Exception as exc:
        # é‡è¯•æœºåˆ¶
        if self.request.retries < self.max_retries:
            raise self.retry(countdown=60, exc=exc)
        else:
            return {"status": "failed", "error": str(exc)}

@celery_app.task
def process_image_task(image_path: str, filters: list):
    """å›¾ç‰‡å¤„ç†ä»»åŠ¡"""
    # æ¨¡æ‹Ÿå›¾ç‰‡å¤„ç†
    processed_path = f"processed_{image_path}"
    return {
        "original_path": image_path,
        "processed_path": processed_path,
        "filters_applied": filters
    }

@celery_app.task
def generate_report_task(user_id: int, report_type: str):
    """ç”ŸæˆæŠ¥å‘Šä»»åŠ¡"""
    # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ
    import time
    time.sleep(10)  # æ¨¡æ‹Ÿé•¿æ—¶é—´å¤„ç†
    
    return {
        "user_id": user_id,
        "report_type": report_type,
        "report_url": f"/reports/{user_id}_{report_type}.pdf",
        "generated_at": datetime.utcnow().isoformat()
    }

# åœ¨APIä¸­ä½¿ç”¨ä»»åŠ¡
from fastapi import APIRouter, BackgroundTasks

router = APIRouter(prefix="/tasks", tags=["tasks"])

@router.post("/send-email")
async def send_email(to_email: str, subject: str, content: str):
    # å¼‚æ­¥æ‰§è¡Œä»»åŠ¡
    task = send_email_task.delay(to_email, subject, content)
    
    return {
        "task_id": task.id,
        "status": "queued",
        "message": "Email task queued successfully"
    }

@router.get("/task-status/{task_id}")
async def get_task_status(task_id: str):
    # è·å–ä»»åŠ¡çŠ¶æ€
    task = celery_app.AsyncResult(task_id)
    
    if task.state == 'PENDING':
        response = {
            "task_id": task_id,
            "state": task.state,
            "status": "Task is waiting to be processed"
        }
    elif task.state == 'PROGRESS':
        response = {
            "task_id": task_id,
            "state": task.state,
            "current": task.info.get('current', 0),
            "total": task.info.get('total', 1),
            "status": task.info.get('status', '')
        }
    elif task.state == 'SUCCESS':
        response = {
            "task_id": task_id,
            "state": task.state,
            "result": task.result
        }
    else:  # FAILURE
        response = {
            "task_id": task_id,
            "state": task.state,
            "error": str(task.info)
        }
    
    return response
```

### 3. æ¶ˆæ¯é˜Ÿåˆ—

```python
from templates.cache import MessageQueue
import asyncio

# åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
message_queue = MessageQueue(
    broker_url="redis://localhost:6379/0",
    queue_name="notifications"
)

# å‘å¸ƒæ¶ˆæ¯
async def publish_notification(user_id: int, message: str, notification_type: str):
    notification = {
        "user_id": user_id,
        "message": message,
        "type": notification_type,
        "timestamp": datetime.utcnow().isoformat()
    }
    
    await message_queue.publish("user.notification", notification)
    print(f"Notification published for user {user_id}")

# æ¶ˆè´¹æ¶ˆæ¯
async def consume_notifications():
    async def handle_notification(message):
        notification = message['body']
        print(f"Processing notification: {notification}")
        
        # å¤„ç†é€šçŸ¥é€»è¾‘
        if notification['type'] == 'email':
            await send_email_notification(notification)
        elif notification['type'] == 'push':
            await send_push_notification(notification)
        elif notification['type'] == 'sms':
            await send_sms_notification(notification)
    
    await message_queue.consume("user.notification", handle_notification)

# å¯åŠ¨æ¶ˆè´¹è€…
async def start_consumer():
    await consume_notifications()

# åœ¨åå°ä»»åŠ¡ä¸­è¿è¡Œ
if __name__ == "__main__":
    asyncio.run(start_consumer())
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. åˆ†å¸ƒå¼é”

```python
from templates.cache import DistributedLock
import asyncio

# åˆ†å¸ƒå¼é”ä½¿ç”¨
async def process_user_data(user_id: int):
    lock_key = f"process_user:{user_id}"
    
    async with DistributedLock(redis_manager, lock_key, timeout=30) as lock:
        if lock.acquired:
            print(f"Processing user {user_id}...")
            
            # æ‰§è¡Œéœ€è¦äº’æ–¥çš„æ“ä½œ
            await update_user_balance(user_id)
            await send_notification(user_id)
            
            print(f"User {user_id} processing completed")
        else:
            print(f"Could not acquire lock for user {user_id}")

# æ‰‹åŠ¨é”ç®¡ç†
async def manual_lock_example():
    lock = DistributedLock(redis_manager, "my_resource", timeout=60)
    
    try:
        acquired = await lock.acquire()
        if acquired:
            # æ‰§è¡Œéœ€è¦é”ä¿æŠ¤çš„æ“ä½œ
            await critical_operation()
        else:
            print("Could not acquire lock")
    finally:
        await lock.release()
```

### 2. ç¼“å­˜ç­–ç•¥

```python
from templates.cache import CacheStrategy, LRUCache, TTLCache

# LRUç¼“å­˜ç­–ç•¥
lru_cache = LRUCache(max_size=1000)

@lru_cache.cached
async def get_user_profile(user_id: int):
    # ä»æ•°æ®åº“è·å–ç”¨æˆ·èµ„æ–™
    return await db.get_user(user_id)

# TTLç¼“å­˜ç­–ç•¥
ttl_cache = TTLCache(default_ttl=300)  # 5åˆ†é’Ÿè¿‡æœŸ

@ttl_cache.cached
async def get_api_data(endpoint: str):
    # ä»å¤–éƒ¨APIè·å–æ•°æ®
    return await external_api.get(endpoint)

# å¤šçº§ç¼“å­˜
class MultiLevelCache:
    def __init__(self):
        self.l1_cache = {}  # å†…å­˜ç¼“å­˜
        self.l2_cache = redis_manager  # Redisç¼“å­˜
    
    async def get(self, key: str):
        # å…ˆæ£€æŸ¥L1ç¼“å­˜
        if key in self.l1_cache:
            return self.l1_cache[key]
        
        # å†æ£€æŸ¥L2ç¼“å­˜
        value = await self.l2_cache.get(key)
        if value is not None:
            # å›å¡«L1ç¼“å­˜
            self.l1_cache[key] = value
            return value
        
        return None
    
    async def set(self, key: str, value, timeout: int = 300):
        # åŒæ—¶è®¾ç½®L1å’ŒL2ç¼“å­˜
        self.l1_cache[key] = value
        await self.l2_cache.set(key, value, timeout)

multi_cache = MultiLevelCache()
```

### 3. ä»»åŠ¡è°ƒåº¦

```python
from templates.cache import TaskScheduler
from celery.schedules import crontab

# å®šæœŸä»»åŠ¡é…ç½®
celery_app.conf.beat_schedule = {
    'cleanup-expired-sessions': {
        'task': 'tasks.cleanup_expired_sessions',
        'schedule': crontab(minute=0, hour=2),  # æ¯å¤©å‡Œæ™¨2ç‚¹
    },
    'send-daily-reports': {
        'task': 'tasks.send_daily_reports',
        'schedule': crontab(minute=0, hour=9),  # æ¯å¤©ä¸Šåˆ9ç‚¹
    },
    'backup-database': {
        'task': 'tasks.backup_database',
        'schedule': crontab(minute=0, hour=3, day_of_week=1),  # æ¯å‘¨ä¸€å‡Œæ™¨3ç‚¹
    },
    'process-analytics': {
        'task': 'tasks.process_analytics',
        'schedule': 30.0,  # æ¯30ç§’
    },
}

# åŠ¨æ€ä»»åŠ¡è°ƒåº¦
class DynamicTaskScheduler:
    def __init__(self, celery_app):
        self.celery_app = celery_app
        self.scheduled_tasks = {}
    
    def schedule_task(self, task_name: str, task_func, schedule, **kwargs):
        """åŠ¨æ€è°ƒåº¦ä»»åŠ¡"""
        self.scheduled_tasks[task_name] = {
            'task': task_func,
            'schedule': schedule,
            'kwargs': kwargs
        }
        
        # æ›´æ–°Celeryé…ç½®
        self.celery_app.conf.beat_schedule[task_name] = {
            'task': task_func,
            'schedule': schedule,
            **kwargs
        }
    
    def remove_task(self, task_name: str):
        """ç§»é™¤è°ƒåº¦ä»»åŠ¡"""
        if task_name in self.scheduled_tasks:
            del self.scheduled_tasks[task_name]
            del self.celery_app.conf.beat_schedule[task_name]

scheduler = DynamicTaskScheduler(celery_app)

# ä½¿ç”¨åŠ¨æ€è°ƒåº¦
scheduler.schedule_task(
    'user-reminder',
    'tasks.send_user_reminder',
    crontab(minute=0, hour=18),  # æ¯å¤©ä¸‹åˆ6ç‚¹
    args=[user_id]
)
```

### 4. æ¶ˆæ¯è·¯ç”±å’Œè¿‡æ»¤

```python
from templates.cache import MessageRouter, MessageFilter

# æ¶ˆæ¯è·¯ç”±å™¨
class NotificationRouter(MessageRouter):
    def __init__(self):
        super().__init__()
        self.routes = {
            'user.email': 'email_queue',
            'user.sms': 'sms_queue',
            'user.push': 'push_queue',
            'admin.alert': 'admin_queue'
        }
    
    def route_message(self, routing_key: str, message: dict):
        queue_name = self.routes.get(routing_key, 'default_queue')
        return queue_name

# æ¶ˆæ¯è¿‡æ»¤å™¨
class PriorityFilter(MessageFilter):
    def filter(self, message: dict) -> bool:
        priority = message.get('priority', 'normal')
        return priority in ['high', 'urgent']

class UserTypeFilter(MessageFilter):
    def __init__(self, allowed_user_types: list):
        self.allowed_user_types = allowed_user_types
    
    def filter(self, message: dict) -> bool:
        user_type = message.get('user_type', 'regular')
        return user_type in self.allowed_user_types

# ä½¿ç”¨è·¯ç”±å’Œè¿‡æ»¤
router = NotificationRouter()
priority_filter = PriorityFilter()
vip_filter = UserTypeFilter(['vip', 'premium'])

async def send_filtered_notification(message: dict):
    # åº”ç”¨è¿‡æ»¤å™¨
    if priority_filter.filter(message) and vip_filter.filter(message):
        # ç¡®å®šè·¯ç”±
        queue = router.route_message(message['type'], message)
        
        # å‘é€åˆ°æŒ‡å®šé˜Ÿåˆ—
        await message_queue.publish_to_queue(queue, message)
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç¼“å­˜é”®è®¾è®¡

```python
# å¥½çš„ç¼“å­˜é”®è®¾è®¡
class CacheKeyBuilder:
    @staticmethod
    def user_profile(user_id: int) -> str:
        return f"user:profile:{user_id}"
    
    @staticmethod
    def user_permissions(user_id: int) -> str:
        return f"user:permissions:{user_id}"
    
    @staticmethod
    def api_response(endpoint: str, params: dict) -> str:
        param_str = "&".join(f"{k}={v}" for k, v in sorted(params.items()))
        return f"api:{endpoint}:{hashlib.md5(param_str.encode()).hexdigest()}"
    
    @staticmethod
    def session_data(session_id: str) -> str:
        return f"session:{session_id}"

# ç¼“å­˜ç‰ˆæœ¬æ§åˆ¶
class VersionedCache:
    def __init__(self, redis_manager, version: int = 1):
        self.redis = redis_manager
        self.version = version
    
    def _versioned_key(self, key: str) -> str:
        return f"v{self.version}:{key}"
    
    async def get(self, key: str):
        return await self.redis.get(self._versioned_key(key))
    
    async def set(self, key: str, value, timeout: int = 300):
        return await self.redis.set(self._versioned_key(key), value, timeout)
    
    async def invalidate_version(self):
        """ä½¿å½“å‰ç‰ˆæœ¬çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ"""
        pattern = f"v{self.version}:*"
        await self.redis.delete_pattern(pattern)
        self.version += 1
```

### 2. é”™è¯¯å¤„ç†å’Œé‡è¯•

```python
# ç¼“å­˜é™çº§ç­–ç•¥
class CacheWithFallback:
    def __init__(self, primary_cache, fallback_cache):
        self.primary = primary_cache
        self.fallback = fallback_cache
    
    async def get(self, key: str):
        try:
            return await self.primary.get(key)
        except Exception as e:
            logger.warning(f"Primary cache failed: {e}, using fallback")
            try:
                return await self.fallback.get(key)
            except Exception as e2:
                logger.error(f"Fallback cache also failed: {e2}")
                return None
    
    async def set(self, key: str, value, timeout: int = 300):
        tasks = []
        try:
            tasks.append(self.primary.set(key, value, timeout))
        except Exception as e:
            logger.warning(f"Primary cache set failed: {e}")
        
        try:
            tasks.append(self.fallback.set(key, value, timeout))
        except Exception as e:
            logger.warning(f"Fallback cache set failed: {e}")
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

# ä»»åŠ¡é‡è¯•ç­–ç•¥
@celery_app.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3, 'countdown': 60})
def robust_task(self, data):
    try:
        # æ‰§è¡Œä»»åŠ¡é€»è¾‘
        result = process_data(data)
        return result
    except TemporaryError as exc:
        # ä¸´æ—¶é”™è¯¯ï¼Œé‡è¯•
        logger.warning(f"Temporary error in task: {exc}")
        raise self.retry(countdown=60)
    except PermanentError as exc:
        # æ°¸ä¹…é”™è¯¯ï¼Œä¸é‡è¯•
        logger.error(f"Permanent error in task: {exc}")
        raise exc
```

### 3. æ€§èƒ½ç›‘æ§

```python
from templates.cache import CacheMetrics
import time

class MonitoredCache:
    def __init__(self, cache, metrics):
        self.cache = cache
        self.metrics = metrics
    
    async def get(self, key: str):
        start_time = time.time()
        try:
            result = await self.cache.get(key)
            
            if result is not None:
                self.metrics.record_hit(key)
            else:
                self.metrics.record_miss(key)
            
            return result
        finally:
            duration = time.time() - start_time
            self.metrics.record_operation_time('get', duration)
    
    async def set(self, key: str, value, timeout: int = 300):
        start_time = time.time()
        try:
            return await self.cache.set(key, value, timeout)
        finally:
            duration = time.time() - start_time
            self.metrics.record_operation_time('set', duration)

# ç¼“å­˜ç»Ÿè®¡
class CacheStats:
    def __init__(self):
        self.hits = 0
        self.misses = 0
        self.operations = {}
    
    def record_hit(self, key: str):
        self.hits += 1
    
    def record_miss(self, key: str):
        self.misses += 1
    
    def record_operation_time(self, operation: str, duration: float):
        if operation not in self.operations:
            self.operations[operation] = []
        self.operations[operation].append(duration)
    
    def get_hit_ratio(self) -> float:
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0
    
    def get_avg_operation_time(self, operation: str) -> float:
        times = self.operations.get(operation, [])
        return sum(times) / len(times) if times else 0
```

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•å¤„ç†ç¼“å­˜é›ªå´©ï¼Ÿ

A: ä½¿ç”¨éšæœºè¿‡æœŸæ—¶é—´å’Œç¼“å­˜é¢„çƒ­ï¼š

```python
import random

async def set_with_jitter(key: str, value, base_timeout: int = 300):
    # æ·»åŠ éšæœºæŠ–åŠ¨ï¼Œé¿å…åŒæ—¶è¿‡æœŸ
    jitter = random.randint(0, base_timeout // 10)
    timeout = base_timeout + jitter
    await redis_manager.set(key, value, timeout)

# ç¼“å­˜é¢„çƒ­
async def warm_up_cache():
    critical_keys = ['popular_products', 'featured_content', 'user_preferences']
    
    for key in critical_keys:
        if not await redis_manager.exists(key):
            data = await fetch_data_for_key(key)
            await set_with_jitter(key, data, 3600)
```

### Q: å¦‚ä½•å¤„ç†ç¼“å­˜ç©¿é€ï¼Ÿ

A: ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨å’Œç©ºå€¼ç¼“å­˜ï¼š

```python
from templates.cache import BloomFilter

bloom_filter = BloomFilter(capacity=1000000, error_rate=0.1)

async def get_with_bloom_filter(key: str):
    # å…ˆæ£€æŸ¥å¸ƒéš†è¿‡æ»¤å™¨
    if not bloom_filter.might_contain(key):
        return None  # è‚¯å®šä¸å­˜åœ¨
    
    # æ£€æŸ¥ç¼“å­˜
    cached_value = await redis_manager.get(key)
    if cached_value is not None:
        return cached_value
    
    # ä»æ•°æ®åº“è·å–
    db_value = await get_from_database(key)
    
    if db_value is not None:
        await redis_manager.set(key, db_value, 3600)
        bloom_filter.add(key)
    else:
        # ç¼“å­˜ç©ºå€¼ï¼Œé˜²æ­¢ç©¿é€
        await redis_manager.set(key, "NULL", 300)
    
    return db_value
```

### Q: å¦‚ä½•ç›‘æ§Celeryä»»åŠ¡ï¼Ÿ

A: ä½¿ç”¨Flowerå’Œè‡ªå®šä¹‰ç›‘æ§ï¼š

```bash
# å®‰è£…Flower
pip install flower

# å¯åŠ¨Flowerç›‘æ§
celery -A your_app flower --port=5555
```

```python
# è‡ªå®šä¹‰ä»»åŠ¡ç›‘æ§
class TaskMonitor:
    def __init__(self, celery_app):
        self.celery_app = celery_app
    
    def get_active_tasks(self):
        inspect = self.celery_app.control.inspect()
        return inspect.active()
    
    def get_scheduled_tasks(self):
        inspect = self.celery_app.control.inspect()
        return inspect.scheduled()
    
    def get_worker_stats(self):
        inspect = self.celery_app.control.inspect()
        return inspect.stats()

monitor = TaskMonitor(celery_app)
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [APIå¼€å‘æ¨¡å—ä½¿ç”¨æŒ‡å—](api.md)
- [æ•°æ®åº“æ¨¡å—ä½¿ç”¨æŒ‡å—](database.md)
- [ç›‘æ§æ—¥å¿—æ¨¡å—ä½¿ç”¨æŒ‡å—](monitoring.md)
- [æ€§èƒ½ä¼˜åŒ–å»ºè®®](best-practices/performance.md)
- [æµ‹è¯•ç­–ç•¥æŒ‡å—](best-practices/testing.md)

---

å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ [GitHub Issues](https://github.com/your-username/python-backend-templates/issues) æˆ–æäº¤æ–°çš„é—®é¢˜ã€‚